# Loss function for computer vision tasks

Computer vision tasks in deep learning require distinct approaches to measuring error, as both the nature of the data and the objectives vary considerably. These tasks can be broadly categorized into discriminative and generative tasks.

- `Discriminative tasks` include `classification`, `detection`, `recognition`, and `segmentation`. For example, 
  - `image classification` focuses on assigning the correct label to an image, while 
  - `object detection` extends this by also identifying object locations within the image. 
  - `Semantic segmentation` goes further by assigning a label to every pixel, requiring loss functions that promote `spatial coherence` and `fine-grained` accuracy.

- `Generative tasks` involve producing new data from various input modalities such as text, audio, or images. Image generation often relies on `adversarial frameworks`, where loss functions capture the trade-off between `realism` and `fidelity` by balancing `generated` and `real data`.

Beyond vision, other domains such as tabular data prediction and time series forecasting typically employ regression-oriented loss functions to handle continuous outputs and capture temporal dependencies.

In this section, we examine the diverse range of loss functions designed for these tasks, highlighting their suitability to specific requirements. A deeper understanding of these functions enables researchers to make informed choices in model selection, tuning, and improvement, thereby enhancing the effectiveness of predictive frameworks.







## Loss function per architecture


















































































































































